{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "scrolled": true,
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<h1>Machine learning using Neural networks to predict eye state data</h1>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!-- <p>The purpose of this project is to get more familiar with an eeg dataset and learn more about data manipulation. The dataset is slipt into 15 differents columns with the last being the target values (0,1). The target values represent the state of the eye, being open or closed. The other data represents the value of an eeg node which gets the value of the electrical activity in that sector surrounding the node.<br> -->\n",
    "This dataset is located in the UCI database found <a href='https://archive.ics.uci.edu/ml/datasets/EEG+Eye+State'>here</a>\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>The purpose of the nodes and locations</h2>\n",
    "<p>The nodes used in this dataset are located in the red filled nodes shown below in Figure 1.<br>\n",
    "\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src='data/eeg_eye_state_map.png' alt='eeg_eye_state_map'>Figure 1</img>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# import libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy.io.arff import loadarff\n",
    "from scipy import stats\n",
    "\n",
    "from keras.utils import normalize\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "# from keras.optimizers import SGD\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.preprocessing import StandardScaler\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Load in the data frame\n",
    "raw_data = loadarff('data/EEG Eye State.arff')\n",
    "df_data = pd.DataFrame(raw_data[0])\n",
    "# df_data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In order to pre-process the data I split the data into two sets. The data and the targets. The targets here are 1 or 0, meaning is the eye open or closed?</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Preprocess Data\n",
    "data_targets=df_data.iloc[:,-1]\n",
    "data=df_data.iloc[:,:-1]\n",
    "\n",
    "# standardize data (z-score)\n",
    "# data=stats.zscore(data)\n",
    "data = normalize(data, axis=1)\n",
    "# print(data)\n",
    "\n",
    "# convert targets into 1 or 0\n",
    "s = pd.Series(data_targets)\n",
    "data_targets=pd.get_dummies(s)\n",
    "data_targets=data_targets.iloc[:,1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p>In order to split into training and test data I use the method train_test_split() which randomizes the data while splitting it into a training and testing data set.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# split the data\n",
    "xTrain, xTest, yTrain, yTest = train_test_split(data, data_targets, test_size = 0.3, random_state = 25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "dense_142 (Dense)            (None, 28)                420       \n",
      "_________________________________________________________________\n",
      "dense_143 (Dense)            (None, 1)                 29        \n",
      "=================================================================\n",
      "Total params: 449\n",
      "Trainable params: 449\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n",
      "Epoch 1/10\n",
      "11984/11984 [==============================] - 2s 167us/step - loss: 0.6965 - acc: 0.5543\n",
      "Epoch 2/10\n",
      "11984/11984 [==============================] - 0s 20us/step - loss: 0.3366 - acc: 0.5733\n",
      "Epoch 3/10\n",
      "11984/11984 [==============================] - 0s 19us/step - loss: 0.2615 - acc: 0.5801: 0s - loss: 0.2739 - acc: 0.57\n",
      "Epoch 4/10\n",
      "11984/11984 [==============================] - 0s 19us/step - loss: 0.2417 - acc: 0.5879\n",
      "Epoch 5/10\n",
      "11984/11984 [==============================] - 0s 19us/step - loss: 0.2350 - acc: 0.5983\n",
      "Epoch 6/10\n",
      "11984/11984 [==============================] - 0s 19us/step - loss: 0.2374 - acc: 0.6101\n",
      "Epoch 7/10\n",
      "11984/11984 [==============================] - 0s 20us/step - loss: 0.2461 - acc: 0.6186\n",
      "Epoch 8/10\n",
      "11984/11984 [==============================] - 0s 24us/step - loss: 0.2475 - acc: 0.6254: 0s - loss: 0.2220 - acc: 0.6\n",
      "Epoch 9/10\n",
      "11984/11984 [==============================] - 0s 19us/step - loss: 0.2468 - acc: 0.6287: 0s - loss: 0.3386 - acc: 0.636 - ETA: 0s - loss: 0.2778 - acc: 0.6\n",
      "Epoch 10/10\n",
      "11984/11984 [==============================] - 0s 20us/step - loss: 0.2357 - acc: 0.6337\n",
      "2996/2996 [==============================] - 1s 210us/step\n",
      "0.529372497458006\n"
     ]
    }
   ],
   "source": [
    "# create model\n",
    "model = Sequential()\n",
    "model.add(Dense(28, activation='relu', input_dim=14))\n",
    "# model.add(Dense(14))\n",
    "model.add(Dense(1)\n",
    "model.summary()\n",
    "\n",
    "model.compile(loss='mse', optimizer='adam', metrics=['accuracy'])\n",
    "model.fit(xTrain, yTrain,epochs=10,batch_size=100)\n",
    "score, acc = model.evaluate(xTest, yTest, batch_size=100)\n",
    "print(acc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "file_extension": ".py",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "mimetype": "text/x-python",
  "name": "python",
  "npconvert_exporter": "python",
  "pygments_lexer": "ipython3",
  "version": 3,
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {},
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
